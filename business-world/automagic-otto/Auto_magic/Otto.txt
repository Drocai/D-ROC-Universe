Okay, I understand you want the complete solution laid out. Generating the entire, fully functional, debugged code for a complex project like "AutoMagic" in a single response is highly challenging due to the intricate nature of integrating multiple APIs, handling authentication securely, managing potential errors from each service, and the sheer volume of code required. Real-world development involves building, testing, and refining components iteratively.
However, I can provide you with the complete structural blueprint, including the full project setup, necessary files, required libraries, and the skeleton of the main Python script (automagic.py) with all the functions defined (but needing implementation). This gives you the entire framework to build upon.
AutoMagic Project - Complete Setup & Code Skeleton
1. Project Structure (in your AutoMagic folder):
AutoMagic/
│
├── generated_images/
├── generated_audio/
├── generated_video_clips/
├── final_videos/
├── logs/
│
├── automagic.py         # Main application script
├── .env                 # Stores API keys and configuration (DO NOT COMMIT TO )
└── requirements.txt     # Lists Python dependencies

2. requirements.txt File:
Create this file in the AutoMagic folder and paste the following library list into it. You can install these using pip install -r requirements.txt in the VS Code terminal later.
# requirements.txt

python-dotenv
requests
schedule
Pillow
moviepy
elevenlabs
openai
google-api-python-client
google-auth-oauthlib
google-auth-httplib2
google-generativeai # For Gemini API / VEO 2
# Add any specific TikTok library if identified later
# Add any specific ComfyUI client library if needed, otherwise requests is used

3. .env File (Populate with Placeholders):
Make sure your .env file contains these placeholders. You will need to replace YOUR_..._HERE with your actual credentials later.
# .env - Configuration for AutoMagic

# --- OpenAI API (DALL-E & potentially GPT for text) ---
OPENAI_API_KEY=YOUR_OPENAI_API_KEY_HERE

# --- ElevenLabs API (TTS) ---
ELEVENLABS_API_KEY=YOUR_ELEVENLABS_API_KEY_HERE
ELEVENLABS_VOICE_ID=YOUR_CHOSEN_VOICE_ID_HERE # Find specific voice IDs on their site

# --- Google Cloud / YouTube / Gemini / VEO 2 API ---
GOOGLE_API_KEY=YOUR_GOOGLE_API_KEY_HERE # For Gemini/VEO 2 via Google AI Studio
GOOGLE_CLOUD_PROJECT=YOUR_GOOGLE_CLOUD_PROJECT_ID_HERE
# YouTube OAuth 2.0 Credentials (from Google Cloud Console)
YOUTUBE_CLIENT_ID=YOUR_GOOGLE_CLIENT_ID_HERE
YOUTUBE_CLIENT_SECRET=YOUR_GOOGLE_CLIENT_SECRET_HERE
YOUTUBE_CHANNEL_ID=YOUR_YOUTUBE_CHANNEL_ID_HERE
GOOGLE_API_CREDENTIALS_FILE=youtube_credentials.json # Path where OAuth token will be stored

# --- Kling AI API ---
# (Credentials/method depend on their specific API - Placeholder)
KLING_API_KEY=YOUR_KLING_API_KEY_HERE_IF_APPLICABLE
KLING_API_ENDPOINT=KLING_API_ENDPOINT_URL_HERE_IF_APPLICABLE

# --- Pictory AI API ---
# (Credentials/method depend on their specific API - Placeholder)
PICTORY_API_KEY=YOUR_PICTORY_API_KEY_HERE_IF_APPLICABLE

# --- ComfyUI API ---
# (Address where your ComfyUI instance is running)
COMFYUI_API_ADDRESS=http://127.0.0.1:8188 # Default local, adjust if needed

# --- TikTok API ---
# (Highly dependent on chosen library/method - Placeholders)
TIKTOK_API_KEY=YOUR_TIKTOK_KEY_HERE_IF_APPLICABLE
TIKTOK_SESSION_ID=YOUR_TIKTOK_SESSION_ID_HERE_IF_NEEDED # Common for unofficial APIs

# --- AutoMagic Settings ---
DAILY_RUN_TIME="09:00" # Example: Run daily at 9:00 AM server time
LOG_FILE_PATH="logs/automagic.log"
IMAGE_SAVE_PATH="generated_images/"
AUDIO_SAVE_PATH="generated_audio/"
VIDEO_CLIP_SAVE_PATH="generated_video_clips/"
FINAL_VIDEO_SAVE_PATH="final_videos/"
# Add other settings: default prompts, seasonal themes, character list etc.
SEASON=1 # Example: Start with Season 1
DAY_NUMBER=1 # Example: Start with Day 1

4. automagic.py (Main Script Skeleton):
Paste this entire code block into your automagic.py file in VS Code. This sets up the structure, imports, configuration loading, logging, scheduling, and defines all the functions we need (with placeholders for their actual logic).
import os
import requests
import schedule
import time
import logging
from datetime import datetime
from dotenv import load_dotenv
from PIL import Image # From Pillow
from moviepy.editor import * # Import everything from moviepy
import elevenlabs
import openai
import google.generativeai as genai
from google_auth_oauthlib.flow import InstalledAppFlow
from google.auth.transport.requests import Request
from google.oauth2.credentials import Credentials
from googleapiclient.discovery import build
from googleapiclient.errors import HttpError
from googleapiclient.http import MediaFileUpload

# --- Configuration and Setup ---

def load_config():
    """Loads environment variables from .env file."""
    load_dotenv()
    config = {
        "openai_api_key": os.getenv("OPENAI_API_KEY"),
        "elevenlabs_api_key": os.getenv("ELEVENLABS_API_KEY"),
        "elevenlabs_voice_id": os.getenv("ELEVENLABS_VOICE_ID"),
        "google_api_key": os.getenv("GOOGLE_API_KEY"), # For Gemini/VEO
        "youtube_client_id": os.getenv("YOUTUBE_CLIENT_ID"),
        "youtube_client_secret": os.getenv("YOUTUBE_CLIENT_SECRET"),
        "youtube_channel_id": os.getenv("YOUTUBE_CHANNEL_ID"),
        "google_api_credentials_file": os.getenv("GOOGLE_API_CREDENTIALS_FILE", "youtube_credentials.json"),
        "kling_api_key": os.getenv("KLING_API_KEY"),
        "kling_api_endpoint": os.getenv("KLING_API_ENDPOINT"),
        "pictory_api_key": os.getenv("PICTORY_API_KEY"),
        "comfyui_api_address": os.getenv("COMFYUI_API_ADDRESS"),
        "tiktok_api_key": os.getenv("TIKTOK_API_KEY"),
        "tiktok_session_id": os.getenv("TIKTOK_SESSION_ID"),
        "daily_run_time": os.getenv("DAILY_RUN_TIME", "09:00"),
        "log_file_path": os.getenv("LOG_FILE_PATH", "logs/automagic.log"),
        "image_save_path": os.getenv("IMAGE_SAVE_PATH", "generated_images/"),
        "audio_save_path": os.getenv("AUDIO_SAVE_PATH", "generated_audio/"),
        "video_clip_save_path": os.getenv("VIDEO_CLIP_SAVE_PATH", "generated_video_clips/"),
        "final_video_save_path": os.getenv("FINAL_VIDEO_SAVE_PATH", "final_videos/"),
        "season": int(os.getenv("SEASON", 1)),
        "day_number": int(os.getenv("DAY_NUMBER", 1)),
    }
    # Ensure directories exist
    for path_key in ["log_file_path", "image_save_path", "audio_save_path", "video_clip_save_path", "final_video_save_path"]:
        if config[path_key]:
            os.makedirs(os.path.dirname(config[path_key]), exist_ok=True)

    # Configure Google Generative AI (Gemini/VEO)
    if config["google_api_key"]:
         genai.configure(api_key=config["google_api_key"])
    else:
        logging.warning("Google API Key not found in .env file. Gemini/VEO features will not work.")

    # Configure OpenAI
    if config["openai_api_key"]:
        openai.api_key = config["openai_api_key"]
    else:
         logging.warning("OpenAI API Key not found in .env file. DALL-E features will not work.")

    # Configure ElevenLabs
    if config["elevenlabs_api_key"]:
        elevenlabs.set_api_key(config["elevenlabs_api_key"])
    else:
        logging.warning("ElevenLabs API Key not found in .env file. TTS features will not work.")

    return config

def setup_logging(log_file_path):
    """Sets up logging to file and console."""
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(levelname)s - %(message)s',
        handlers=[
            logging.FileHandler(log_file_path),
            logging.StreamHandler()
        ]
    )
    logging.info("Logging setup complete.")

# --- Content Generation Functions ---

def get_trending_data():
    """Placeholder: Scrapes or uses APIs to find trending sounds, styles, hashtags."""
    logging.info("Fetching trending data...")
    # --- IMPLEMENTATION NEEDED ---
    # This is complex: requires finding reliable sources/APIs for trends
    # For now, return placeholder data or manually defined trends
    trending_sound_path = "path/to/placeholder_trending_sound.mp3" # Placeholder
    trending_hashtags = ["#AI #Automation #Surreal #Affirmation", "#DailyContent"] # Placeholder
    logging.info("Trending data fetched (using placeholders).")
    return trending_sound_path, trending_hashtags

def generate_llm_text(prompt, config):
    """Generates text (affirmation/dialogue) using an LLM API (Gemini)."""
    logging.info(f"Generating LLM text for prompt: {prompt[:50]}...")
    # --- IMPLEMENTATION NEEDED ---
    # Use google.generativeai library
    try:
        # Example using Gemini (replace with actual model and prompt structure)
        # model = genai.GenerativeModel('gemini-1.5-flash') # Or appropriate model
        # response = model.generate_content(prompt)
        # generated_text = response.text
        generated_text = f"Placeholder affirmation for {prompt[:20]}: Be the surreal you wish to see." # Placeholder
        logging.info("LLM text generated successfully.")
        return generated_text
    except Exception as e:
        logging.error(f"Error generating LLM text: {e}")
        return None

def generate_tts_audio(text, voice_id, save_path, config):
    """Generates audio from text using ElevenLabs API."""
    logging.info(f"Generating TTS audio for text: {text[:50]}...")
    if not config["elevenlabs_api_key"] or not voice_id:
        logging.error("ElevenLabs API key or Voice ID missing.")
        return None
    # --- IMPLEMENTATION NEEDED ---
    try:
        # Use elevenlabs library
        # audio = elevenlabs.generate(
        #     text=text,
        #     voice=voice_id,
        #     model="eleven_multilingual_v2" # Or another appropriate model
        # )
        # file_path = os.path.join(save_path, f"audio_{datetime.now().strftime('%Y%m%d_%H%M%S')}.mp3")
        # elevenlabs.save(audio, file_path)

        # Placeholder: Create a dummy file
        file_path = os.path.join(save_path, f"audio_{datetime.now().strftime('%Y%m%d_%H%M%S')}.mp3")
        with open(file_path, 'w') as f: f.write("dummy audio data") # Creates an empty file
        logging.info(f"TTS audio generated and saved to {file_path}")
        return file_path
    except Exception as e:
        logging.error(f"Error generating TTS audio: {e}")
        return None

def generate_dalle_image(prompt, save_path, config):
    """Generates an image using DALL-E API."""
    logging.info(f"Generating DALL-E image for prompt: {prompt[:50]}...")
    if not config["openai_api_key"]:
        logging.error("OpenAI API key missing.")
        return None
    # --- IMPLEMENTATION NEEDED ---
    try:
        # Use openai library (ensure latest version compatibility, e.g., v1.x+)
        # response = openai.images.generate(
        #     model="dall-e-3", # Or dall-e-2
        #     prompt=prompt,
        #     n=1,
        #     size="1024x1024" # Or other supported sizes
        # )
        # image_url = response.data[0].url
        # # Download the image
        # image_response = requests.get(image_url, stream=True)
        # image_response.raise_for_status()
        # file_path = os.path.join(save_path, f"dalle_{datetime.now().strftime('%Y%m%d_%H%M%S')}.png")
        # with open(file_path, 'wb') as f:
        #     for chunk in image_response.iter_content(8192):
        #         f.write(chunk)

        # Placeholder: Create a dummy file
        file_path = os.path.join(save_path, f"dalle_{datetime.now().strftime('%Y%m%d_%H%M%S')}.png")
        Image.new('RGB', (100, 100), color = 'red').save(file_path) # Creates a red square
        logging.info(f"DALL-E image generated and saved to {file_path}")
        return file_path
    except Exception as e:
        logging.error(f"Error generating DALL-E image: {e}")
        return None

def generate_veo_video(prompt, image_path, save_path, config):
    """Generates a video clip using VEO 2 API (via Gemini)."""
    logging.info(f"Generating VEO video for prompt: {prompt[:50]}...")
    if not config["google_api_key"]:
        logging.error("Google API key missing for VEO.")
        return None
    # --- IMPLEMENTATION NEEDED ---
    # Requires specific setup and API calls using google.generativeai for VEO
    # Likely involves uploading the image and providing the text prompt
    # This is complex and needs careful reading of VEO API docs
    try:
        # Placeholder logic
        logging.warning("VEO video generation not implemented - returning placeholder.")
        # Create a dummy video file using MoviePy
        file_path = os.path.join(save_path, f"veo_placeholder_{datetime.now().strftime('%Y%m%d_%H%M%S')}.mp4")
        clip = ColorClip(size=(64,64), color=(0,255,0), duration=5) # Green clip
        clip.write_videofile(file_path, fps=24, logger=None)
        clip.close()
        logging.info(f"VEO placeholder video saved to {file_path}")
        return file_path
    except Exception as e:
        logging.error(f"Error in VEO video generation placeholder: {e}")
        return None

def generate_kling_video(prompt, image_path, save_path, config):
    """Generates a video clip using Kling AI API."""
    logging.info(f"Generating Kling video for prompt: {prompt[:50]}...")
    # --- IMPLEMENTATION NEEDED ---
    # Requires specific API calls to Kling's endpoint using requests
    # Structure depends heavily on Kling's specific API documentation
    logging.warning("Kling video generation not implemented - returning placeholder.")
    # Create a dummy video file using MoviePy
    file_path = os.path.join(save_path, f"kling_placeholder_{datetime.now().strftime('%Y%m%d_%H%M%S')}.mp4")
    clip = ColorClip(size=(64,64), color=(0,0,255), duration=5) # Blue clip
    clip.write_videofile(file_path, fps=24, logger=None)
    clip.close()
    logging.info(f"Kling placeholder video saved to {file_path}")
    return file_path

def run_comfyui_workflow(prompt, save_path, config):
    """Triggers a ComfyUI workflow via its API."""
    logging.info(f"Running ComfyUI workflow for prompt: {prompt[:50]}...")
    if not config["comfyui_api_address"]:
        logging.error("ComfyUI API address missing.")
        return None
    # --- IMPLEMENTATION NEEDED ---
    # Requires structuring a JSON payload representing the ComfyUI workflow
    # and sending it via POST request using the 'requests' library.
    # Then polling for results or using websockets. This is complex.
    logging.warning("ComfyUI workflow execution not implemented - returning placeholder image.")
    file_path = os.path.join(save_path, f"comfyui_placeholder_{datetime.now().strftime('%Y%m%d_%H%M%S')}.png")
    Image.new('RGB', (100, 100), color = 'blue').save(file_path) # Creates a blue square
    logging.info(f"ComfyUI placeholder image saved to {file_path}")
    return file_path # Returning image path as placeholder


# --- Video Assembly Function ---

def assemble_video(image_paths, video_clip_paths, audio_path, text_overlay, music_path, output_path):
    """Assembles the final video using MoviePy."""
    logging.info(f"Assembling final video to {output_path}...")
    # --- IMPLEMENTATION NEEDED ---
    # This involves loading clips, adding audio, text, music using MoviePy
    try:
        clips = []
        # Load generated video clips
        for path in video_clip_paths:
            if path and os.path.exists(path):
                 # Add error handling for corrupted files
                try:
                    clips.append(VideoFileClip(path))
                except Exception as e:
                    logging.error(f"Could not load video clip {path}: {e}")
            else:
                 logging.warning(f"Video clip path not found or invalid: {path}")

        # If no video clips, maybe use generated images as static clips
        if not clips and image_paths:
             for img_path in image_paths:
                 if img_path and os.path.exists(img_path):
                     try:
                         # Make image clip duration match audio or a default
                         clips.append(ImageClip(img_path).set_duration(5)) # Default 5 sec
                     except Exception as e:
                         logging.error(f"Could not load image clip {img_path}: {e}")
                 else:
                     logging.warning(f"Image path not found or invalid: {img_path}")

        if not clips:
            logging.error("No valid video clips or images to assemble.")
            return None

        final_clip = concatenate_videoclips(clips, method="compose")

        # Add Text Overlay
        if text_overlay:
            txt_clip = TextClip(text_overlay, fontsize=70, color='white', font='Arial', bg_color='black', size=final_clip.size)
            # Position the text (e.g., center) and set duration
            txt_clip = txt_clip.set_pos('center').set_duration(final_clip.duration)
            final_clip = CompositeVideoClip([final_clip, txt_clip])

        # Add Voiceover Audio
        if audio_path and os.path.exists(audio_path):
             try:
                voiceover = AudioFileClip(audio_path)
                # Ensure audio doesn't exceed video duration
                if voiceover.duration > final_clip.duration:
                    voiceover = voiceover.subclip(0, final_clip.duration)
                final_clip = final_clip.set_audio(voiceover)
             except Exception as e:
                 logging.error(f"Could not load or set voiceover {audio_path}: {e}")
        else:
            logging.warning(f"Voiceover audio path not found or invalid: {audio_path}")


        # Add Background Music (Placeholder logic)
        if music_path and os.path.exists(music_path):
            try:
                background_music = AudioFileClip(music_path).volumex(0.1) # Lower volume
                # Loop or cut music to match video duration
                if background_music.duration > final_clip.duration:
                     background_music = background_music.subclip(0, final_clip.duration)
                # elif background_music.duration < final_clip.duration:
                    # background_music = background_music.fx(vfx.loop, duration=final_clip.duration) # Requires careful implementation

                # Mix with voiceover if present
                if final_clip.audio:
                    final_audio = CompositeAudioClip([final_clip.audio, background_music])
                    final_clip = final_clip.set_audio(final_audio)
                else:
                    final_clip = final_clip.set_audio(background_music)
            except Exception as e:
                logging.error(f"Could not load or add background music {music_path}: {e}")
        else:
             logging.warning(f"Background music path not found or invalid: {music_path}")


        # Write the final video file
        final_clip.write_videofile(output_path, codec='libx264', audio_codec='aac', fps=24)

        # Close clips to release resources
        for clip in clips:
            clip.close()
        if final_clip.audio: final_clip.audio.close()
        if 'voiceover' in locals() and voiceover: voiceover.close()
        if 'background_music' in locals() and background_music: background_music.close()
        final_clip.close()

        logging.info("Final video assembled successfully.")
        return output_path
    except Exception as e:
        logging.error(f"Error assembling video: {e}")
        # Clean up intermediate clips if possible
        return None


# --- Social Media Posting Functions ---

def get_youtube_service(config):
    """Authenticates and builds the YouTube API service object using OAuth 2.0."""
    CLIENT_SECRETS_FILE = "client_secret.json" # Should contain client_id, client_secret etc. from Google Cloud Console
    SCOPES = ['https://www.googleapis.com/auth/youtube.upload']
    API_SERVICE_NAME = 'youtube'
    API_VERSION = 'v3'
    CREDENTIALS_FILE = config["google_api_credentials_file"]

    creds = None
    # The file CREDENTIALS_FILE stores the user's access and refresh tokens, and is
    # created automatically when the authorization flow completes for the first time.
    if os.path.exists(CREDENTIALS_FILE):
        creds = Credentials.from_authorized_user_file(CREDENTIALS_FILE, SCOPES)
    # If there are no (valid) credentials available, let the user log in.
    if not creds or not creds.valid:
        if creds and creds.expired and creds.refresh_token:
            try:
                creds.refresh(Request())
            except Exception as e:
                logging.error(f"Error refreshing credentials: {e}. Need to re-authenticate.")
                # If refresh fails, force re-authentication
                flow = InstalledAppFlow.from_client_secrets_file(CLIENT_SECRETS_FILE, SCOPES)
                # Note: This requires user interaction in the terminal/browser the first time!
                # This won't work in a fully unattended Replit environment without modifications
                # or using a service account approach (more complex).
                creds = flow.run_local_server(port=0)
        else:
             # Check if client_secret.json exists
            if not os.path.exists(CLIENT_SECRETS_FILE):
                 logging.error(f"OAuth secrets file '{CLIENT_SECRETS_FILE}' not found. Please download it from Google Cloud Console.")
                 return None
            flow = InstalledAppFlow.from_client_secrets_file(CLIENT_SECRETS_FILE, SCOPES)
            creds = flow.run_local_server(port=0) # Requires user interaction
        # Save the credentials for the next run
        with open(CREDENTIALS_FILE, 'w') as token:
            token.write(creds.to_json())
        logging.info(f"Credentials saved to {CREDENTIALS_FILE}")

    try:
        service = build(API_SERVICE_NAME, API_VERSION, credentials=creds)
        logging.info("YouTube service object created successfully.")
        return service
    except Exception as e:
        logging.error(f"Could not build YouTube service: {e}")
        return None


def upload_to_youtube(video_path, title, description, tags, config):
    """Uploads a video to YouTube."""
    logging.info(f"Uploading '{title}' to YouTube...")
    youtube = get_youtube_service(config)
    if not youtube:
        logging.error("Failed to get YouTube service. Aborting upload.")
        return False

    if not os.path.exists(video_path):
        logging.error(f"Video file not found: {video_path}")
        return False

    # --- IMPLEMENTATION NEEDED ---
    # Use youtube.videos().insert() method
    try:
        body = {
            'snippet': {
                'title': title,
                'description': description,
                'tags': tags,
                'categoryId': '22' # Example: People & Blogs category ID
            },
            'status': {
                'privacyStatus': 'public', # Or 'private', 'unlisted'
                'selfDeclaredMadeForKids': False # Important: Set appropriately
            }
        }
        media = MediaFileUpload(video_path, chunksize=-1, resumable=True)

        request = youtube.videos().insert(
            part=','.join(body.keys()),
            body=body,
            media_body=media
        )

        response = None
        while response is None:
            status, response = request.next_chunk()
            if status:
                logging.info(f"Uploaded {int(status.progress() * 100)}%")

        logging.info(f"YouTube upload successful! Video ID: {response['id']}")
        return True

    except HttpError as e:
        logging.error(f"An HTTP error {e.resp.status} occurred:\n{e.content}")
        return False
    except Exception as e:
        logging.error(f"An unexpected error occurred during YouTube upload: {e}")
        return False


def upload_to_tiktok(video_path, caption, config):
    """Uploads a video to TikTok."""
    logging.info(f"Uploading video to TikTok (Caption: {caption[:50]}...)...")
    # --- IMPLEMENTATION NEEDED ---
    # This is challenging as official TikTok upload APIs are restricted.
    # Often requires unofficial libraries (like tiktok-uploader) or browser automation (Selenium).
    # Unofficial methods are prone to breaking.
    # Example using a hypothetical library:
    # try:
    #     from tiktok_uploader import upload_video
    #     upload_video(video_path, description=caption, cookies='cookies.txt') # Requires cookies setup
    #     logging.info("TikTok upload potentially successful (using unofficial library).")
    #     return True
    # except ImportError:
    #     logging.warning("TikTok uploader library not found.")
    #     return False
    # except Exception as e:
    #     logging.error(f"Error uploading to TikTok: {e}")
    #     return False
    logging.warning("TikTok upload functionality is not implemented.")
    return False

def generate_metadata(content_theme, config):
    """Generates title, description, tags/hashtags using an LLM."""
    logging.info("Generating metadata...")
    prompt = f"Generate a catchy YouTube title, a short YouTube description, YouTube tags (comma-separated), a TikTok caption, and TikTok hashtags (space-separated) for a short surreal affirmation video about: {content_theme}. Include trending hashtags: {config.get('trending_hashtags_placeholder', '#AI #Surreal')}" # Use fetched trends later
    # --- IMPLEMENTATION NEEDED ---
    # Call generate_llm_text or similar
    metadata_text = generate_llm_text(prompt, config)
    # Parse the response (this needs robust parsing)
    try:
        # Example basic parsing (highly dependent on LLM output format)
        lines = metadata_text.split('\n')
        title = lines[0].replace("Title:","").strip()
        description = lines[1].replace("Description:","").strip()
        tags = [tag.strip() for tag in lines[2].replace("Tags:","").split(',')]
        caption = lines[3].replace("Caption:","").strip()
        hashtags = lines[4].replace("Hashtags:","").strip() # Keep as space separated string for TikTok
        logging.info("Metadata generated.")
        return {"title": title, "description": description, "tags": tags, "caption": caption, "hashtags": hashtags}
    except Exception as e:
        logging.error(f"Error parsing metadata: {e}. Using defaults.")
        return {"title": f"Surreal Affirmation: {content_theme}", "description": "Daily dose of weird wisdom.", "tags": ["AI", "Surreal", "Affirmation"], "caption": f"Think about it... #AI #Surreal", "hashtags": "#AI #Surreal #Affirmation"}


# --- Main Job Function ---

def daily_job(config):
    """The main function to run the daily automation task."""
    logging.info("Starting daily AutoMagic job...")
    today_str = datetime.now().strftime('%Y%m%d_%H%M%S')

    # 1. Get Trends (Using Placeholders for now)
    trending_sound_path, trending_hashtags = get_trending_data()
    # Update config temporarily or pass trends along
    config['trending_hashtags_placeholder'] = " ".join(trending_hashtags) # Example

    # 2. Generate Content Theme/Text (Based on Season/Day)
    # --- Needs logic to determine today's character/theme ---
    content_theme = f"Season {config['season']} Day {config['day_number']} - Office Plant Wisdom" # Placeholder
    affirmation_text = generate_llm_text(f"Generate surreal affirmation for: {content_theme}", config)
    if not affirmation_text:
        logging.error("Failed to generate text. Aborting job.")
        return

    # 3. Generate Audio
    audio_file = generate_tts_audio(affirmation_text, config["elevenlabs_voice_id"], config["audio_save_path"], config)
    if not audio_file:
        logging.warning("Failed to generate audio. Proceeding without voiceover.")

    # 4. Generate Image (e.g., using DALL-E)
    image_prompt = f"Hyperrealistic, surreal image representing: {content_theme}. {affirmation_text[:50]}" # Create better prompts
    image_file = generate_dalle_image(image_prompt, config["image_save_path"], config)
    if not image_file:
        logging.error("Failed to generate base image. Aborting job.")
        return

    # 5. Generate Video Clip (e.g., using VEO 2)
    video_prompt = f"An 8-second video clip animating the concept: {content_theme}. Style: raw, gritty, mind-bending."
    video_clip_file = generate_veo_video(video_prompt, image_file, config["video_clip_save_path"], config)
    # --- Add logic here to maybe try Kling or ComfyUI if VEO fails or isn't used ---
    # video_clip_file = generate_kling_video(...)
    # visual_asset = run_comfyui_workflow(...) # Might return image or video

    if not video_clip_file:
         logging.error("Failed to generate video clip. Aborting job.")
         # Clean up generated assets if needed
         if audio_file and os.path.exists(audio_file): os.remove(audio_file)
         if image_file and os.path.exists(image_file): os.remove(image_file)
         return

    # 6. Assemble Final Video
    final_video_filename = f"AutoMagic_{today_str}.mp4"
    final_video_path = os.path.join(config["final_video_save_path"], final_video_filename)
    assembled_path = assemble_video(
        image_paths=[image_file], # Or multiple images from ComfyUI
        video_clip_paths=[video_clip_file], # Or multiple clips
        audio_path=audio_file,
        text_overlay=affirmation_text,
        music_path=trending_sound_path, # Use the trending sound
        output_path=final_video_path
    )

    if not assembled_path:
        logging.error("Failed to assemble final video. Aborting job.")
         # Clean up generated assets
        if audio_file and os.path.exists(audio_file): os.remove(audio_file)
        if image_file and os.path.exists(image_file): os.remove(image_file)
        if video_clip_file and os.path.exists(video_clip_file): os.remove(video_clip_file)
        return

    # 7. Generate Metadata
    metadata = generate_metadata(content_theme, config)

    # 8. Upload to Platforms
    youtube_success = upload_to_youtube(
        assembled_path,
        metadata["title"],
        metadata["description"],
        metadata["tags"],
        config
    )
    tiktok_success = upload_to_tiktok(
        assembled_path,
        metadata["caption"] + " " + metadata["hashtags"], # Combine caption & hashtags
        config
    )

    # 9. Cleanup (Optional: delete intermediate files)
    # if youtube_success or tiktok_success: # Only cleanup if successful upload happened
    #    if audio_file and os.path.exists(audio_file): os.remove(audio_file)
    #    if image_file and os.path.exists(image_file): os.remove(image_file)
    #    if video_clip_file and os.path.exists(video_clip_file): os.remove(video_clip_file)
    #    # Keep the final video or delete it too? Depends on preference.
    #    # if os.path.exists(assembled_path): os.remove(assembled_path)
    #    logging.info("Intermediate files cleaned up.")

    # 10. Update Day/Season Counter (Needs persistent storage like a file or DB)
    # config['day_number'] += 1
    # if config['day_number'] > 33: # Example season length
    #    config['day_number'] = 1
    #    config['season'] += 1
    # --- Save updated config state ---
    logging.info("AutoMagic daily job finished.")


# --- Scheduler ---

if __name__ == "__main__":
    app_config = load_config()
    setup_logging(app_config["log_file_path"])

    logging.info(f"AutoMagic application started. Scheduling job for {app_config['daily_run_time']} daily.")

    # Schedule the job
    schedule.every().day.at(app_config["daily_run_time"]).do(daily_job, config=app_config)

    # Run once immediately for testing (optional)
    # logging.info("Running job once immediately for testing...")
    # daily_job(app_config)
    # logging.info("Initial test run complete.")

    # Keep the script running to check the schedule
    while True:
        schedule.run_pending()
        time.sleep(60) # Check every minute

Instructions & Next Steps:
 * Review the Code: Look through automagic.py. You'll see the overall structure, imports, configuration loading, logging setup, scheduler, and all the necessary functions defined with pass or placeholder comments like # --- IMPLEMENTATION NEEDED ---.
 * Obtain API Keys & Credentials: This is the most crucial manual step. You need to visit the websites for OpenAI (DALL-E), ElevenLabs, Google Cloud (for YouTube API, Gemini/VEO API Key), Kling AI, Pictory AI, and potentially TikTok Developer portal. Create accounts, find the API sections, generate keys/credentials, and enable the necessary APIs (especially on Google Cloud - YouTube Data API v3, Google Generative AI API).
 * Set up YouTube OAuth 2.0:
   * Go to Google Cloud Console.
   * Create a project (if you don't have one).
   * Enable the "YouTube Data API v3".
   * Go to "Credentials".
   * Create "OAuth 2.0 Client ID". Choose "Desktop app".
   * Download the client_secret.json file. Place this file in your AutoMagic folder.
   * Fill in the YOUTUBE_CLIENT_ID and YOUTUBE_CLIENT_SECRET in your .env file from the credentials you created (or they might be inside the .json file).
 * Fill .env File: Carefully replace all the YOUR_..._HERE placeholders in your .env file with the actual keys and IDs you obtained. Choose a default voice ID from ElevenLabs. Set the COMFYUI_API_ADDRESS correctly (if running locally, the default is probably fine).
 * Implement Functions Incrementally: This is where the main development happens. You (or I, if you ask me to generate specific functions one by one) need to fill in the Python code inside each placeholder function in automagic.py.
   * Start Simple: Maybe begin with generate_llm_text or generate_tts_audio.
   * Test Each Part: Run and test each function individually after implementing it to make sure it works before moving on.
   * Authentication: Pay close attention to how each library handles API keys (some use environment variables automatically, others need explicit setup like openai.api_key = ...). The YouTube OAuth flow (get_youtube_service) will require you to run the script once manually where you can access a web browser to authorize the application. It will then save a youtube_credentials.json file (or whatever you named it in .env).
   * API Calls: Use the requests library or the specific client libraries (openai, elevenlabs, google-generativeai) to make calls, sending the right data and handling the responses.
   * ComfyUI/Kling/Pictory/TikTok: These require looking up their specific API documentation (if available and public) to structure the requests correctly. TikTok is often the hardest to automate reliably.
   * MoviePy: Implement the logic to load files, combine them, add overlays/audio. Test with small files first.
 * Debugging: Use VS Code's debugger and the logs generated in the logs/ folder to fix errors as they arise.
 * Run on Replit: Once the code is developed and tested (at least partially) in VS Code, ensure your AutoMagic folder (including .env, requirements.txt, and the script) is synced or uploaded to your "Otto" Repl on Replit. Run pip install -r requirements.txt in the Replit Shell. Then, run the script using the "Run" button in Replit for the actual daily execution using cloud resources.
This provides the complete structure and the roadmap. The next phase involves the detailed implementation within each function, starting with getting your API keys configured in the .env file.
